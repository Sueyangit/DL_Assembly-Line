{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 极客云训练深度学习模型 Assembly Line\n",
    "> * 上传数据和代码\n",
    "> * 运行程序\n",
    "> * 下载训练好的模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 数据预处理后，将模型的输入数据保存为文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('embedding_weights.pkl','wb')as f:\n",
    "    pickle.dump(embedding_weights,f)\n",
    "    print('embedding_weights'+'存入文件成功')\n",
    "\n",
    "with open('x_test.pkl','wb')as f:\n",
    "    pickle.dump(x_test,f) \n",
    "    print('x_test'+'存入文件成功')\n",
    "    \n",
    "with open('y_test.pkl','wb')as f:\n",
    "    pickle.dump(y_test,f)\n",
    "    print('y_test'+'存入文件成功')\n",
    "\n",
    "with open('y_train.pkl','wb')as f:\n",
    "    pickle.dump(y_train,f)  \n",
    "    print('y_train'+'存入文件成功')\n",
    "    \n",
    "with open('x_train.pkl','wb')as f:\n",
    "    pickle.dump(x_train,f)\n",
    "    print('x_train'+'存入文件成功')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 输入数据的读入\n",
    "##### 注意初始化一些必要参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#以下是 模型需要的数据一共五个大文件，加上两个参数   \n",
    "with open('/input/x_test.pkl','rb')as f:\n",
    "    x_test=pickle.load(f)\n",
    "    print('x_test'+'载入文件成功')\n",
    "\n",
    "with open('/input/y_test.pkl','rb')as f:\n",
    "    y_test=pickle.load(f)\n",
    "    print('y_test'+'载入文件成功')\n",
    "\n",
    "    \n",
    "with open('/input/x_train.pkl','rb')as f:\n",
    "    x_train=pickle.load(f)\n",
    "    print('x_train'+'载入文件成功')\n",
    "\n",
    "    \n",
    "with open('/input/y_train.pkl','rb')as f:\n",
    "    y_train=pickle.load(f) \n",
    "    print('y_train'+'载入文件成功')\n",
    "\n",
    "    \n",
    "with open('/input/embedding_weights.pkl','rb')as f:\n",
    "    embedding_weights=pickle.load(f) \n",
    "    print('embedding_weights'+'载入文件成功')\n",
    "\n",
    " \n",
    "len_vocabulary_inv=103943\n",
    "y_shape_1=202\n",
    "print(\"Load data success...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ---------------------- Parameters section -------------------\n",
    "#\n",
    "# Model type. See Kim Yoon's Convolutional Neural Networks for Sentence Classification, Section 3\n",
    "model_type = \"CNN-non-static\"  # CNN-rand|CNN-non-static|CNN-static\n",
    "#model_type = \"CNN-static\"  # CNN-rand|CNN-non-static|CNN-static\n",
    "\n",
    "# Model Hyperparameters\n",
    "#embedding_dim = 100\n",
    "embedding_dim = 500\n",
    "\n",
    "filter_sizes = (3, 8)\n",
    "#filter_sizes = (6, 8)\n",
    "#num_filters = 128\n",
    "#num_filters = 10\n",
    "num_filters = 50\n",
    "dropout_prob = (0.5, 0.8)\n",
    "hidden_dims = 50\n",
    "\n",
    "# Training parameters\n",
    "#batch_size = 32\n",
    "batch_size = 64\n",
    "num_epochs = 50\n",
    "#num_epochs = 1\n",
    "\n",
    "# Prepossessing parameters\n",
    "#sequence_length = 1500   #400\n",
    "sequence_length = 500\n",
    "#sequence_length = 400   #400\n",
    "\n",
    "#max_words = 20000   #5000\n",
    "\n",
    "# Word2Vec parameters (see train_word2vec)\n",
    "min_word_count = 1\n",
    "context = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#==============================================================================\n",
    "# # Build model\n",
    "#==============================================================================\n",
    "def text_cnn():\n",
    "    if model_type == \"CNN-static\":\n",
    "        input_shape = (sequence_length, embedding_dim)\n",
    "    else:\n",
    "        input_shape = (sequence_length,)\n",
    "    \n",
    "    model_input = Input(shape=input_shape)\n",
    "    \n",
    "    # Static model does not have embedding layer\n",
    "#    嵌入层Embedding被定义为网络的第一个隐藏层。它必须指定3个参数：\n",
    "#    它必须指定3个参数：\n",
    "#    1.input_dim：这是文本数据中词汇的大小。 \n",
    "#    2.output_dim：这是嵌入单词的向量空间的大小。它为每个单词定义了该层的输出向量的大小。例如，它可以是32或100甚至更大。根据你的问题来定。\n",
    "#    3.input_length：这是输入序列的长度，正如你为Keras模型的任何输入层定义的那样。例如，如果你的所有输入文档包含1000个单词，则为1000\n",
    "    if model_type == \"CNN-static\":\n",
    "        z = model_input\n",
    "    else:\n",
    "        z = Embedding(len_vocabulary_inv, embedding_dim, input_length=sequence_length, name=\"embedding\")(model_input)\n",
    "    \n",
    "    z = Dropout(dropout_prob[0])(z)\n",
    "    \n",
    "    # Convolutional block\n",
    "    conv_blocks = []\n",
    "    for sz in filter_sizes:\n",
    "        conv = Convolution1D(filters=num_filters,\n",
    "                             kernel_size=sz,\n",
    "                             padding=\"valid\",\n",
    "                             activation=\"relu\",\n",
    "                             strides=1)(z)\n",
    "        conv = MaxPooling1D(pool_size=2)(conv)\n",
    "        conv = Flatten()(conv)\n",
    "        conv_blocks.append(conv)\n",
    "    z = Concatenate()(conv_blocks) if len(conv_blocks) > 1 else conv_blocks[0]\n",
    "    \n",
    "    z = Dropout(dropout_prob[1])(z)\n",
    "    z = Dense(hidden_dims, activation=\"relu\")(z)\n",
    "    model_output = Dense(y_shape_1, activation=\"softmax\")(z)\n",
    "    \n",
    "    model = Model(model_input, model_output)\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "    #==============================================================================\n",
    "    # # Initialize weights with word2vec\n",
    "    #==============================================================================\n",
    "    if model_type == \"CNN-non-static\":\n",
    "        weights = np.array([v for v in embedding_weights.values()])\n",
    "        print(\"Initializing embedding layer with word2vec weights, shape\", weights.shape)\n",
    "        embedding_layer = model.get_layer(\"embedding\")\n",
    "        embedding_layer.set_weights([weights])\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 训练及模型保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#==============================================================================\n",
    "# # Train the model\n",
    "#==============================================================================\n",
    "print(\"training...\")\n",
    "model=text_cnn()\n",
    "model.fit(x_train, y_train,validation_split=0.2, batch_size=batch_size, epochs=num_epochs, verbose=2,class_weight='auto')\n",
    "\n",
    "print(\"pridicting...\")\n",
    "scores = model.evaluate(x_test,y_test)\n",
    "print('test_loss:%f,accuracy: %f'%(scores[0],scores[1]))\n",
    "\n",
    "print(\"saving accu_textcnnmodel\")\n",
    "model.save('/data/textcnn_keras_law/accu_textcnn.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 上传数据和代码\n",
    "> * 使用Winscp，上传到/data文件夹，再把数据都复制到/input文件夹,\n",
    "> * \"cp空格/data/xxx/mydata.pkl空格/input\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.6 日志（可选）\n",
    "> * 程序打印输出的内容将不再出现在终端上，而是保存在log文件里"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#日志\n",
    "import sys\n",
    "f_handler=open('out.log', 'w')\n",
    "sys.stdout=f_handler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 最终日志结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_test载入文件成功\n",
    "y_test载入文件成功\n",
    "x_train载入文件成功\n",
    "y_train载入文件成功\n",
    "embedding_weights载入文件成功\n",
    "Load data success...\n",
    "training...\n",
    "Initializing embedding layer with word2vec weights, shape (103943, 500)\n",
    "Train on 10963 samples, validate on 2741 samples\n",
    "Epoch 1/50\n",
    "10s - loss: 4.6456 - acc: 0.0506 - val_loss: 4.4022 - val_acc: 0.0905\n",
    "Epoch 2/50\n",
    "8s - loss: 3.9241 - acc: 0.1506 - val_loss: 3.4705 - val_acc: 0.2328\n",
    "Epoch 3/50\n",
    "8s - loss: 2.8834 - acc: 0.3070 - val_loss: 2.6227 - val_acc: 0.3652\n",
    "Epoch 4/50\n",
    "8s - loss: 2.0999 - acc: 0.4601 - val_loss: 2.1469 - val_acc: 0.4943\n",
    "Epoch 5/50\n",
    "8s - loss: 1.5671 - acc: 0.5739 - val_loss: 1.9125 - val_acc: 0.5509\n",
    "Epoch 6/50\n",
    "8s - loss: 1.2058 - acc: 0.6651 - val_loss: 1.7807 - val_acc: 0.5834\n",
    "Epoch 7/50\n",
    "8s - loss: 0.9553 - acc: 0.7253 - val_loss: 1.7046 - val_acc: 0.6053\n",
    "Epoch 8/50\n",
    "8s - loss: 0.7701 - acc: 0.7749 - val_loss: 1.7169 - val_acc: 0.6224\n",
    "Epoch 9/50\n",
    "8s - loss: 0.6507 - acc: 0.8130 - val_loss: 1.6808 - val_acc: 0.6425\n",
    "Epoch 10/50\n",
    "8s - loss: 0.5269 - acc: 0.8422 - val_loss: 1.7212 - val_acc: 0.6432\n",
    "Epoch 11/50\n",
    "8s - loss: 0.4769 - acc: 0.8561 - val_loss: 1.7688 - val_acc: 0.6461\n",
    "Epoch 12/50\n",
    "8s - loss: 0.4127 - acc: 0.8773 - val_loss: 1.7394 - val_acc: 0.6571\n",
    "Epoch 13/50\n",
    "8s - loss: 0.3655 - acc: 0.8864 - val_loss: 1.8485 - val_acc: 0.6592\n",
    "Epoch 14/50\n",
    "8s - loss: 0.3443 - acc: 0.8964 - val_loss: 1.9085 - val_acc: 0.6571\n",
    "Epoch 15/50\n",
    "8s - loss: 0.3084 - acc: 0.9041 - val_loss: 1.9446 - val_acc: 0.6545\n",
    "Epoch 16/50\n",
    "8s - loss: 0.2740 - acc: 0.9164 - val_loss: 2.0552 - val_acc: 0.6662\n",
    "Epoch 17/50\n",
    "8s - loss: 0.2545 - acc: 0.9217 - val_loss: 2.0268 - val_acc: 0.6603\n",
    "Epoch 18/50\n",
    "8s - loss: 0.2339 - acc: 0.9287 - val_loss: 2.0788 - val_acc: 0.6611\n",
    "Epoch 19/50\n",
    "8s - loss: 0.2265 - acc: 0.9308 - val_loss: 2.0727 - val_acc: 0.6669\n",
    "Epoch 20/50\n",
    "8s - loss: 0.2102 - acc: 0.9335 - val_loss: 2.1260 - val_acc: 0.6665\n",
    "Epoch 21/50\n",
    "8s - loss: 0.2084 - acc: 0.9403 - val_loss: 2.1841 - val_acc: 0.6651\n",
    "Epoch 22/50\n",
    "8s - loss: 0.2035 - acc: 0.9393 - val_loss: 2.1881 - val_acc: 0.6779\n",
    "Epoch 23/50\n",
    "8s - loss: 0.1997 - acc: 0.9403 - val_loss: 2.2483 - val_acc: 0.6636\n",
    "Epoch 24/50\n",
    "8s - loss: 0.1800 - acc: 0.9484 - val_loss: 2.2823 - val_acc: 0.6665\n",
    "Epoch 25/50\n",
    "8s - loss: 0.1807 - acc: 0.9476 - val_loss: 2.2828 - val_acc: 0.6698\n",
    "Epoch 26/50\n",
    "8s - loss: 0.1720 - acc: 0.9500 - val_loss: 2.3505 - val_acc: 0.6749\n",
    "Epoch 27/50\n",
    "8s - loss: 0.1748 - acc: 0.9484 - val_loss: 2.3895 - val_acc: 0.6713\n",
    "Epoch 28/50\n",
    "8s - loss: 0.1692 - acc: 0.9507 - val_loss: 2.3226 - val_acc: 0.6691\n",
    "Epoch 29/50\n",
    "8s - loss: 0.1721 - acc: 0.9515 - val_loss: 2.3920 - val_acc: 0.6731\n",
    "Epoch 30/50\n",
    "8s - loss: 0.1838 - acc: 0.9480 - val_loss: 2.3880 - val_acc: 0.6757\n",
    "Epoch 31/50\n",
    "8s - loss: 0.1858 - acc: 0.9476 - val_loss: 2.4445 - val_acc: 0.6764\n",
    "Epoch 32/50\n",
    "8s - loss: 0.1766 - acc: 0.9488 - val_loss: 2.4153 - val_acc: 0.6717\n",
    "Epoch 33/50\n",
    "8s - loss: 0.1598 - acc: 0.9550 - val_loss: 2.5468 - val_acc: 0.6585\n",
    "Epoch 34/50\n",
    "8s - loss: 0.1404 - acc: 0.9600 - val_loss: 2.4975 - val_acc: 0.6830\n",
    "Epoch 35/50\n",
    "8s - loss: 0.1458 - acc: 0.9579 - val_loss: 2.5573 - val_acc: 0.6757\n",
    "Epoch 36/50\n",
    "8s - loss: 0.1517 - acc: 0.9569 - val_loss: 2.5365 - val_acc: 0.6738\n",
    "Epoch 37/50\n",
    "8s - loss: 0.1699 - acc: 0.9524 - val_loss: 2.6479 - val_acc: 0.6789\n",
    "Epoch 38/50\n",
    "8s - loss: 0.1529 - acc: 0.9570 - val_loss: 2.6829 - val_acc: 0.6746\n",
    "Epoch 39/50\n",
    "8s - loss: 0.1404 - acc: 0.9620 - val_loss: 2.7596 - val_acc: 0.6662\n",
    "Epoch 40/50\n",
    "8s - loss: 0.1520 - acc: 0.9614 - val_loss: 2.6221 - val_acc: 0.6735\n",
    "Epoch 41/50\n",
    "8s - loss: 0.1593 - acc: 0.9554 - val_loss: 2.7454 - val_acc: 0.6713\n",
    "Epoch 42/50\n",
    "8s - loss: 0.1345 - acc: 0.9637 - val_loss: 2.7122 - val_acc: 0.6844\n",
    "Epoch 43/50\n",
    "8s - loss: 0.1336 - acc: 0.9666 - val_loss: 2.6978 - val_acc: 0.6808\n",
    "Epoch 44/50\n",
    "8s - loss: 0.1481 - acc: 0.9615 - val_loss: 2.6845 - val_acc: 0.6873\n",
    "Epoch 45/50\n",
    "8s - loss: 0.1450 - acc: 0.9642 - val_loss: 2.7867 - val_acc: 0.6753\n",
    "Epoch 46/50\n",
    "8s - loss: 0.1292 - acc: 0.9665 - val_loss: 2.7196 - val_acc: 0.6815\n",
    "Epoch 47/50\n",
    "8s - loss: 0.1244 - acc: 0.9670 - val_loss: 2.8670 - val_acc: 0.6782\n",
    "Epoch 48/50\n",
    "8s - loss: 0.1601 - acc: 0.9623 - val_loss: 2.8403 - val_acc: 0.6771\n",
    "Epoch 49/50\n",
    "8s - loss: 0.1532 - acc: 0.9619 - val_loss: 2.7765 - val_acc: 0.6859\n",
    "Epoch 50/50\n",
    "8s - loss: 0.1333 - acc: 0.9648 - val_loss: 2.8925 - val_acc: 0.6706\n",
    "pridicting...\n",
    "\n",
    "  32/3427 [..............................] - ETA: 1s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
    " 384/3427 [==>...........................] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
    " 736/3427 [=====>........................] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
    "1088/3427 [========>.....................] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
    "1440/3427 [===========>..................] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
    "1792/3427 [==============>...............] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
    "2144/3427 [=================>............] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
    "2464/3427 [====================>.........] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
    "2816/3427 [=======================>......] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
    "3168/3427 [==========================>...] - ETA: 0stest_loss:2.805001,accuracy: 0.681938\n",
    "saving accu_textcnnmodel\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
